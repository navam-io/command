'2025-10-19T12:24:29.326925':
  bedrock:
    sonnet3:
      ask:
        details: Command executed successfully
        prompt: How old is the oldest pyramid?
        response_time: 1.4337468147277832
        status: Success
        token_count: 53
'2025-10-19T12:24:30.100460':
  bedrock:
    haiku3:
      ask:
        details: Command executed successfully
        prompt: How old is the oldest pyramid?
        response_time: 0.754523754119873
        status: Success
        token_count: 33
'2025-10-19T12:24:33.821648':
  claude:
    sonnet:
      ask:
        details: Command executed successfully
        prompt: How old is the oldest pyramid?
        response_time: 3.68231201171875
        status: Success
        token_count: 97
'2025-10-19T12:24:38.566891':
  claude:
    sonnet4-5:
      ask:
        details: Command executed successfully
        prompt: How old is the oldest pyramid?
        response_time: 4.712478160858154
        status: Success
        token_count: 78
'2025-10-19T12:25:05.071365':
  bedrock:
    sonnet3:
      ask:
        details: Command executed successfully
        prompt: How old is the oldest pyramid?
        response_time: 1.240034818649292
        status: Success
        token_count: 50
'2025-10-19T12:25:05.992854':
  bedrock:
    haiku3:
      ask:
        details: Command executed successfully
        prompt: How old is the oldest pyramid?
        response_time: 0.8969638347625732
        status: Success
        token_count: 39
'2025-10-19T12:25:09.946361':
  claude:
    sonnet:
      ask:
        details: Command executed successfully
        prompt: How old is the oldest pyramid?
        response_time: 3.9030020236968994
        status: Success
        token_count: 97
'2025-10-19T12:25:14.737315':
  claude:
    sonnet4-5:
      ask:
        details: Command executed successfully
        prompt: How old is the oldest pyramid?
        response_time: 4.75763463973999
        status: Success
        token_count: 78
'2025-10-19T12:25:17.255594':
  claude:
    opus:
      ask:
        details: Command executed successfully
        prompt: How old is the oldest pyramid?
        response_time: 2.4846408367156982
        status: Success
        token_count: 40
'2025-10-19T12:25:38.245923':
  claude:
    opus4-1:
      ask:
        details: Command executed successfully
        prompt: How old is the oldest pyramid?
        response_time: 20.956581115722656
        status: Success
        token_count: 35
'2025-10-19T12:25:39.298286':
  claude:
    haiku:
      ask:
        details: Command executed successfully
        prompt: How old is the oldest pyramid?
        response_time: 1.0159480571746826
        status: Success
        token_count: 33
'2025-10-19T12:25:41.215560':
  claude:
    haiku4-5:
      ask:
        details: Command executed successfully
        prompt: How old is the oldest pyramid?
        response_time: 1.8780648708343506
        status: Success
        token_count: 75
'2025-10-19T12:25:41.470953':
  gemini:
    gemini-pro:
      ask:
        details: 404 models/gemini-1.5-pro is not found for API version v1beta, or
          is not supported for generateContent. Call ListModels to see the list of
          available models and their supported methods.
        prompt: How old is the oldest pyramid?
        response_time: .inf
        status: Error
        token_count: N/A
'2025-10-19T12:25:41.692867':
  gemini:
    gemini-flash:
      ask:
        details: 404 models/gemini-1.5-flash is not found for API version v1beta,
          or is not supported for generateContent. Call ListModels to see the list
          of available models and their supported methods.
        prompt: How old is the oldest pyramid?
        response_time: .inf
        status: Error
        token_count: N/A
'2025-10-19T12:25:41.724230':
  groq:
    mixtral:
      ask:
        details: Client.__init__() got an unexpected keyword argument 'proxies'
        prompt: How old is the oldest pyramid?
        response_time: .inf
        status: Error
        token_count: N/A
'2025-10-19T12:25:41.771769':
  ollama:
    llama:
      ask:
        details: Command executed successfully
        prompt: How old is the oldest pyramid?
        response_time: 0.027312040328979492
        status: Success
        token_count: 0
'2025-10-19T12:25:41.792020':
  ollama:
    llava:
      ask:
        details: Command executed successfully
        prompt: How old is the oldest pyramid?
        response_time: 0.0032930374145507812
        status: Success
        token_count: 0
'2025-10-19T12:25:41.810795':
  ollama:
    mistral:
      ask:
        details: Command executed successfully
        prompt: How old is the oldest pyramid?
        response_time: 0.0029511451721191406
        status: Success
        token_count: 0
'2025-10-19T12:25:41.829783':
  ollama:
    gemma:
      ask:
        details: Command executed successfully
        prompt: How old is the oldest pyramid?
        response_time: 0.0030608177185058594
        status: Success
        token_count: 0
'2025-10-19T12:25:41.847377':
  ollama:
    qwen:
      ask:
        details: Command executed successfully
        prompt: How old is the oldest pyramid?
        response_time: 0.0022270679473876953
        status: Success
        token_count: 0
'2025-10-19T12:25:44.240598':
  openai:
    gpt4o:
      ask:
        details: Command executed successfully
        prompt: How old is the oldest pyramid?
        response_time: 2.373249053955078
        status: Success
        token_count: 32
'2025-10-19T12:25:45.635279':
  openai:
    gpt4mini:
      ask:
        details: Command executed successfully
        prompt: How old is the oldest pyramid?
        response_time: 1.3600177764892578
        status: Success
        token_count: 45
'2025-10-19T12:25:45.671131':
  perplexity:
    sonar:
      ask:
        details: PERPLEXITY_KEY not found. Please set it in .env.local file or as
          an environment variable.
        prompt: How old is the oldest pyramid?
        response_time: .inf
        status: Error
        token_count: N/A
'2025-10-19T12:27:20.711263':
  claude:
    sonnet:
      vision:
        details: Command executed successfully
        prompt: How many people are in the image?
        response_time: 3.4064981937408447
        status: Success
        token_count: 128
'2025-10-19T12:27:25.253154':
  claude:
    sonnet4-5:
      vision:
        details: Command executed successfully
        prompt: How many people are in the image?
        response_time: 4.490278959274292
        status: Success
        token_count: 66
'2025-10-19T12:27:28.973690':
  claude:
    opus:
      vision:
        details: Command executed successfully
        prompt: How many people are in the image?
        response_time: 3.679532051086426
        status: Success
        token_count: 75
'2025-10-19T12:27:36.210968':
  claude:
    opus4-1:
      vision:
        details: Command executed successfully
        prompt: How many people are in the image?
        response_time: 7.1952338218688965
        status: Success
        token_count: 83
'2025-10-19T12:27:37.167947':
  claude:
    haiku:
      vision:
        details: Command executed successfully
        prompt: How many people are in the image?
        response_time: 0.9165117740631104
        status: Success
        token_count: 29
'2025-10-19T12:27:39.819691':
  claude:
    haiku4-5:
      vision:
        details: Command executed successfully
        prompt: How many people are in the image?
        response_time: 2.6128180027008057
        status: Success
        token_count: 80
'2025-10-19T12:27:40.281435':
  gemini:
    gemini-pro:
      vision:
        details: 404 models/gemini-1.5-pro is not found for API version v1beta, or
          is not supported for generateContent. Call ListModels to see the list of
          available models and their supported methods.
        prompt: How many people are in the image?
        response_time: .inf
        status: Error
        token_count: N/A
'2025-10-19T12:27:40.631946':
  gemini:
    gemini-flash:
      vision:
        details: 404 models/gemini-1.5-flash is not found for API version v1beta,
          or is not supported for generateContent. Call ListModels to see the list
          of available models and their supported methods.
        prompt: How many people are in the image?
        response_time: .inf
        status: Error
        token_count: N/A
'2025-10-19T12:27:40.686587':
  ollama:
    llava:
      vision:
        details: Command executed successfully
        prompt: How many people are in the image?
        response_time: 0.018460988998413086
        status: Success
        token_count: 0
'2025-10-19T12:27:43.904941':
  openai:
    gpt4o:
      vision:
        details: Command executed successfully
        prompt: How many people are in the image?
        response_time: 3.181749105453491
        status: Success
        token_count: 10
'2025-10-19T12:27:45.916121':
  openai:
    gpt4mini:
      vision:
        details: Command executed successfully
        prompt: How many people are in the image?
        response_time: 1.976046085357666
        status: Success
        token_count: 14
